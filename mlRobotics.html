<!doctype html>
<html lang="en">

<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-KyZXEAg3QhqLMpG8r+8fhAXLRk2vvoC2f3B09zVXn8CA5QIVfZOJ3BCsw2P0p/We" crossorigin="anonymous">

    <title>ML Section</title>
    <link rel="shortcut icon" href="favicon(1).ico" type="image/x-icon">
</head>

<body>


    <style>
        body {
          background-image: url('Bg2.png');
          background-repeat: no-repeat;
          background-attachment: fixed;
          background-size: 100% 100%;
        }
        </style>



    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
        <div class="container-fluid">
            <a class="navbar-brand" href="/WebGeek/">
                <img src="Photos/Logo1.png" height="30">
            </a>
            <ul>
            </ul>
            <ul>
            </ul>
            <ul>
            </ul>
            <ul>
            </ul>
            <ul>
            </ul>
            <ul>
            </ul>
            <ul>
            </ul>
            <ul>
            </ul>
            <ul>
            </ul>
            <ul>
            </ul>
            <ul>
            </ul>
            <ul>
            </ul>
            <ul>
            </ul>
            <ul>
            </ul>
            <ul>
            </ul>
            <ul>
            </ul>
            <ul>
            </ul>
            <ul>
            </ul>
            <ul>
            </ul>
            <ul>
            </ul>
            <ul>
            </ul>
            <ul>
            </ul>
            <ul>
            </ul>
            <ul>
            </ul>
            <ul>
            </ul>
            <ul>
            </ul>
            <ul>
            </ul>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse"
                data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false"
                aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="navbar-nav me-auto mb-2 mb-lg-0">
                    <li class="nav-item" {padding-left:30px; padding-right:30px;}>
                        <a class="nav-link" href="main.html" target="_main1">Home</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link active" aria-current="page" href="innovation.html" target="_main2">Innovation</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="news.html" target="_main3">News</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="aiRobotics.html" target="_main6">AI in Robotics</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="mlRobotics.html" target="_main7">ML in Robotics</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="ds.html" target="_main8">DS in Robotics</a>
                    </li>

                </ul>
            </div>
        </div>
    </nav>

    <div class="container">
        <h1><b><u>How ML is Being Used in Robotics:</u></b></h1>
        <br><h4>
            <img src="ml.jpg">
            <br><br>
            <b>As the term “machine learning” has heated up, interest in “robotics” (as expressed in Google Trends) has not altered much over the last three years. So how much of a place is there for machine learning in robotics?</b></h4>
    
            <br><br>
            <h2><b><font color='gold'>4 Tenets of Artificial intelligence and Machine Learning in Robotics:</font></h2>
            <h3>There are four areas of robotic processes that AI and machine learning are impacting to make current applications more efficient and profitable. The scope of AI in robotics includes:</b></h3>

            <h3><font color='gold'>1. Vision:</font></h3>
            <h4><b>AI is helping robots detect items they’ve never seen before and recognize objects with far greater detail.</b>
            <br>
            <h3><font color='gold'>2. Grasping:</h3></font>
            <h4><b>Robots are also grasping items they’ve never seen before with AI and machine learning helping them determine the best position and orientation to grasp an object.</b></h4>
            <br>
            <h3><font color='gold'>3. Motion Control:</font></h3>
            <h4><b>Machine learning helps robots with dynamic interaction and obstacle avoidance to maintain productivity. </b></h4>
            <br>
            <h3><font color='gold'>4. Data:</font></h3>
            <h4><b>AI and machine learning both help robots understand physical and logistical data patterns to be proactive and act accordingly.</b></h4>
            <br><br><br>
            <h3>The following overview of machine learning applications in robotics highlights five key areas where machine learning has had a significant impact on robotic technologies, both at present and in the development stages for future uses. Though by no means inclusive, the purpose of the summary is to give readers a taste for the types of machine learning applications that exist in robotics and stimulate the desire for further research in these and other areas.</h3>
            <br><br>
            <h2><b><u>5 Current Machine Learning Applications in Robotics:</u></b></h2>
                <h3><font color='gold'>1 – Computer Vision:</font></h3>
                <h4><b>Though related, some would argue the correct term is machine vision or robot vision rather than computer vision, because “robots seeing” involves more than just computer algorithms; engineers and roboticists also have to account for camera hardware that allow robots to process physical data. Robot vision is very closely linked to machine vision, which can be given credit for the emergence of robot guidance and automatic inspection systems. The slight difference between the two may be in kinematics as applied to robot vision, which encompasses reference frame calibration and a robot’s ability to physically affect its environment.
                    An influx of big data i.e. visual information available on the web (including annotated/labeled photos and videos) has propelled advances in computer vision, which in turn has helped further machine-learning based structured prediction learning techniques at universities like Carnegie Mellon and elsewhere, leading to robot vision applications like identification and sorting of objects. One offshoot example of this  is anomaly detection with unsupervised learning, such as building systems capable of finding and assessing faults in silicon wafers using convolutional neural networks, as engineered by researchers at the Biomimetic Robotics and Machine Learning Lab, which is part of the nonprofit Assistenzrobotik e.V. in Munich.
                    Extrasensory technologies like radar, lidar, and ultrasound, like those from Nvidia, are also driving the development of 360-degree vision-based systems for autonomous vehicles and drones. </b>
                <br>
                <h3><font color='gold'>2. Imitaion Learning:</h3></font>
                <h4><b>Imitation learning is closely related to observational learning, a behavior exhibited by infants and toddlers. Imitation learning is also an umbrella category for reinforcement learning, or the challenge of getting an agent to act in the world so as to maximize its rewards. Bayesian or probabilistic models are a common feature of this machine learning approach. The question of whether imitation learning could be used for humanoid-like robots was postulated as far back as 1999.
                    Imitation learning has become an integral part of field robotics, in which characteristics of mobility outside a factory setting in domains like domains like construction, agriculture, search and rescue, military, and others, make it challenging to manually program robotic solutions. Examples include inverse optimal control methods, or “programming by demonstration,”which has been applied by CMU and other organizations in the areas of humanoid robotics, legged locomotion, and off-road rough-terrain mobile navigators. Researchers from Arizona State published this video two years ago showing a humanoid robot using imitation learning to acquire different grasping techniques:
                    
                    
                    AI and machine learning are still in their infancy in regards to robotic applications, but they’re already having an important impact.
                    Two Types of Industrial Robot Applications Using Artificial Intelligence and Machine Learning
                    Supply chain and logistics applications are seeing some of the first implementations of AI and machine learning in robotics.
                    In one example, a robotic arm is responsible for handling frozen cases of food that are covered in frost. The frost causes the shape of the objects to change – the robot is not just presented different parts occasionally, it’s being continuously presented with differently shaped parts. AI helps the robot detect and grasp these objects despite the variations in shape.
                    Another prime example of machine learning involves picking and placing over 90,000 different part types in a warehouse. This volume of part types wouldn’t be profitable to automate without machine learning, but now engineers can regularly feed robots images of new parts and the robot can then successfully grasp these part types.
                    AI and machine learning will have a transformative impact on industrial robots. While these technologies are still in their infancy, they will continue to push the boundaries of what’s possible with industrial robotic automation over the next few decades.</b></h4>
                <br>
                <h3><font color='gold'>3 – Self-Supervised Learning:</font></h3>
                <h4><b>Self-supervised learning approaches enable robots to generate their own training examples in order to improve performance; this includes using a priori training and data captured close range to interpret “long-range ambiguous sensor data.” It’s been incorporated into robots and optical devices that can detect and reject objects (dust and snow, for example); identify vegetables and obstacles in rough terrain; and in 3D-scene analysis and modeling vehicle dynamics
                    Watch-Bot is a concrete example, created by researchers from Cornell and Stanford, that uses a 3D sensor (a Kinect), a camera, laptop and laser pointer to detect ‘normal human activity’, which are patterns that it learns through probabilistic methods. Watch-Bot uses a laser pointer to target the object as a reminder (for example, the milk that was left out of the fridge). In initial tests, the bot was able to successfully remind humans 60 percent of time (it has no conception of what it’s doing or why), and the researchers expanded trials by allowing its robot to learn from online videos (called project RoboWatch). </b></h4>
                <br>
                <h3><font color='gold'>4 – Assistive and Medical Technologies:</font></h3>
                <h4><b>An assistive robot (according to Stanford’s David L. Jaffe) is a device that can sense, process sensory information, and perform actions that benefit people with disabilities and seniors (though smart assistive technologies also exist for the general population, such as driver assistance tools). Movement therapy robots provide a diagnostic or therapeutic benefit. Both of these are technologies that are largely (and unfortunately) still confined to the lab, as they’re still cost-prohibitive for most hospitals in the U.S. and abroad. </b></h4>
                <br>
                <h3><font color='gold'>5 – Multi-Agent Learning:</font></h3>
                <h4><b>Coordination and negotiation are key components of multi-agent learning, which involves machine learning-based robots (or agents – this technique has been widely applied to games) that are able to adapt to a shifting landscape of other robots/agents and find “equilibrium strategies.” Examples of multi-agent learning approaches include no-regret learning tools, which involve weighted algorithms that “boost” learning outcomes in multi-agent planning, and learning in market-based, distributed control systems.</b></h4>   
        
        
        
        
        
        
        
        
        
        
        
        </div>
        <br><br><br>
        <footer class="bg-light text-center text-lg-start">
            <div class="text-center p-3" style="background-color: rgba(0, 0, 0, 0.2);">
              © 2022 Copyright:
              <a class="text-dark" href="#" target="_main31">WebGeek.com</a>
            </div>
        </div>       
        </footer>
